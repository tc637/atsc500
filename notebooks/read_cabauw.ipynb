{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the sunrise/sunset calculations you'll need to do:\n",
    "\n",
    "```\n",
    "conda install dateutil\n",
    "conda install ephem\n",
    "```\n",
    "\n",
    "On windows, you can get an ncdump executable [here](http://www.unidata.ucar.edu/software/netcdf/docs/winbin.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from netCDF4 import Dataset\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "filelist=['cesar_nubiscope_cloudcover_la1_t10_v1.0_201407.nc',\n",
    "          'cesar_nubiscope_cloudcover_la1_t10_v1.0_201412.nc',\n",
    "          'cesar_surface_flux_lc1_t10_v1.0_201407.nc',\n",
    "          'cesar_surface_flux_lc1_t10_v1.0_201412.nc',\n",
    "          'cesar_surface_meteo_lc1_t10_v1.0_201407.nc',\n",
    "          'cesar_surface_meteo_lc1_t10_v1.0_201412.nc',\n",
    "          'cesar_tower_meteo_lb1_t10_v1.1_201407.nc',\n",
    "          'cesar_tower_meteo_lb1_t10_v1.1_201412.nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "data_download=True\n",
    "if data_download:\n",
    "    for the_file in filelist:\n",
    "        url='http://clouds.eos.ubc.ca/~phil/docs/atsc500/cabauw/{}'.format(the_file)\n",
    "        urllib.request.urlretrieve(url,the_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The make_date function takes an open CESAR ncfile and turns the time\n",
    "vector from hours past the start date into a python datetime object\n",
    "in UTC.  It uses the dateutil parse function to turn the date_start_of_data\n",
    "string into a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_date(ncfile):\n",
    "    \"\"\"\n",
    "    ncfile:  open netCDF4 Dataset\n",
    "    returns:\n",
    "       numpy array of datetime objects\n",
    "    \"\"\"\n",
    "    the_time=f.variables['time'][...]\n",
    "    start_date=f.variables['product'].date_start_of_data\n",
    "    start_date = parse(start_date)\n",
    "    time_vec=[]\n",
    "    for the_hour in the_time:\n",
    "        time_vec.append(start_date + datetime.timedelta(hours=float(the_hour)))\n",
    "    time_vec=np.array(time_vec)\n",
    "    return time_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all the files and make a dictionary with keys determined\n",
    "by the netcdf file attributes.  Initially the dictionary contains the\n",
    "filename, start_date, lat, lon and start time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_files=glob.glob('cesar*.nc')\n",
    "data_dict={}\n",
    "for the_file in all_files:\n",
    "    with Dataset(the_file,'r') as f:\n",
    "        details=f.variables['iso_dataset']\n",
    "        attributes=details.ncattrs()\n",
    "        attr_dict={}\n",
    "        for attr in attributes:\n",
    "            attr_dict[attr]=getattr(details,attr)\n",
    "        lon=attr_dict['westbound_longitude']\n",
    "        lat=attr_dict['northbound_latitude']\n",
    "        title=attr_dict['title'].split()\n",
    "        the_time = make_date(f)\n",
    "        #\n",
    "        # turn a title like:\n",
    "        #\"CESAR surface fluxes validated and gap filled\"\n",
    "        # into the string: surface_fluxes\n",
    "        #\n",
    "        filetype='{}_{}'.format(*title[1:3])\n",
    "        start_date=f.variables['product'].date_start_of_data\n",
    "        start_date=parse(start_date)\n",
    "        start_month=start_date.strftime('%Y%m')\n",
    "    data_dict[filetype,start_month]=dict(name=the_file,start=start_date,lat=lat,lon=lon,\n",
    "                                         time=the_time)\n",
    "print(data_dict.keys())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now loop through the dictionary and add the flux and tower variables.\n",
    "Each variable is a linear vector of measurements taken every 10 minutes, and\n",
    "for tower variables, at 7 levels.\n",
    "\n",
    "The numpy command:\n",
    "var.reshape(-1,24,6,7)\n",
    "takes the linear vector and folds it into either 28,29,30,31 days (depending on monty)\n",
    "24 hours, 6 10 minute intervals, and 7 levels\n",
    "\n",
    "That allows us to do an hourly average by saying:\n",
    "var.mean(axis=2)  to average over the 6 10 minute measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for the_key in data_dict.keys():\n",
    "    if the_key[0] == 'tower_meteorological':\n",
    "        var_dict=data_dict[the_key]\n",
    "        with Dataset(var_dict['name'],'r') as f:\n",
    "            var_dict['z'] = f.variables['z'][...]\n",
    "            for var in ['F','TA','TD','Q']:\n",
    "                var_dict[var] = f.variables[var][...].reshape(-1,24,6,7)\n",
    "    elif the_key[0] == 'surface_fluxes': \n",
    "        var_dict=data_dict[the_key]\n",
    "        with Dataset(var_dict['name'],'r') as f:\n",
    "            for var in ['H','UST','LE']:\n",
    "                var_dict[var] = f.variables[var][...]\n",
    "    elif the_key[0] == 'meteorological_surface': \n",
    "        var_dict=data_dict[the_key]\n",
    "        with Dataset(var_dict['name'],'r') as f:\n",
    "            for var in ['P0']:\n",
    "                var_dict[var] = f.variables[var][...]\n",
    "    elif the_key[0] == 'scanning_radiometer':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"didn't recognize {}\".format(the_key[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to know sunrise, sunset and solar noon to interpret our\n",
    "data.  Here is how you find these with the \n",
    "[pyephem](http://stackoverflow.com/questions/2637293/calculating-dawn-and-sunset-times-using-pyephem) module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month=['201407','201412']\n",
    "import ephem\n",
    "for the_month in month:\n",
    "    var='tower_meteorological'\n",
    "    tower_dict=data_dict[var,the_month]\n",
    "    start_time=tower_dict['time'][0]\n",
    "    cabauw=ephem.Observer()\n",
    "    cabauw.date=start_time\n",
    "    cabauw.lon = tower_dict['lon']\n",
    "    cabauw.lat = tower_dict['lat']\n",
    "    sunrise=cabauw.next_rising(ephem.Sun())\n",
    "    noon = cabauw.next_transit(ephem.Sun(),start=sunrise)\n",
    "    sunset = cabauw.next_setting(ephem.Sun())\n",
    "    print('sunrise is {} UTC'.format(sunrise))\n",
    "    print('solar noon {} UTC'.format(noon))\n",
    "    print('sunset is {} UTC'.format(sunset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.close('all')\n",
    "    \n",
    "var='tower_meteorological'\n",
    "tower_dict=data_dict[var,the_month]\n",
    "the_times=tower_dict['time'].reshape(-1,24,6)    \n",
    "\n",
    "\n",
    "for the_month in month:\n",
    "    var='tower_meteorological'\n",
    "    tower_dict=data_dict[var,the_month]\n",
    "    hourly_wind_avg=tower_dict['F'].mean(axis=2)\n",
    "    z=tower_dict['z']\n",
    "    \n",
    "    hour=2\n",
    "    fig,ax=plt.subplots(1,2,figsize=(8,6))\n",
    "    ax[0].plot(hourly_wind_avg[:,hour,:].T,z)\n",
    "    ax[0].set(title='hour: {} UTC'.format(hour))\n",
    "    hour=14\n",
    "    ax[1].plot(hourly_wind_avg[:,hour,:].T,z)\n",
    "    ax[1].set(title='hour: {} UTC'.format(hour))\n",
    "    fig.suptitle('{} hourly avg winds'.format(the_month))\n",
    "\n",
    "    #\n",
    "    # date plotting tips at http://matplotlib.org/users/recipes.html\n",
    "    #\n",
    "    var='surface_fluxes'\n",
    "    flux_dict=data_dict[var,the_month]\n",
    "\n",
    "    fig,ax=plt.subplots(1,1,figsize=(8,6))\n",
    "    fig.autofmt_xdate()\n",
    "    ax.plot(flux_dict['time'],flux_dict['H'])\n",
    "    title='sensible heat flux for {}'.format(the_month)\n",
    "    ax.set(title=title,ylabel='H $(W\\,m^{-2})$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}