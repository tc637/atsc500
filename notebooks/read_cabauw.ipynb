{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "To do the sunrise/sunset calculations you'll need to do:\n",
    "\n",
    "```\n",
    "conda install dateutil\n",
    "conda install ephem\n",
    "```\n",
    "\n",
    "On windows, you can get an ncdump executable [here](http://www.unidata.ucar.edu/software/netcdf/docs/winbin.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Read cabauw data\n",
    "\n",
    "This notebook opens and reads two months of cabauw data: July, 2014 and\n",
    "December 2014.  It combines those two days and the measurements we care\n",
    "about in a new file called cabauw_ubc.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from netCDF4 import Dataset\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "filelist=['cesar_nubiscope_cloudcover_la1_t10_v1.0_201407.nc',\n",
    "          'cesar_nubiscope_cloudcover_la1_t10_v1.0_201412.nc',\n",
    "          'cesar_surface_flux_lc1_t10_v1.0_201407.nc',\n",
    "          'cesar_surface_flux_lc1_t10_v1.0_201412.nc',\n",
    "          'cesar_surface_meteo_lc1_t10_v1.0_201407.nc',\n",
    "          'cesar_surface_meteo_lc1_t10_v1.0_201412.nc',\n",
    "          'cesar_tower_meteo_lb1_t10_v1.1_201407.nc',\n",
    "          'cesar_tower_meteo_lb1_t10_v1.1_201412.nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "data_download=True\n",
    "if data_download:\n",
    "    for the_file in filelist:\n",
    "        url='http://clouds.eos.ubc.ca/~phil/docs/atsc500/cabauw/{}'.format(the_file)\n",
    "        urllib.request.urlretrieve(url,the_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The make_date function takes an open CESAR ncfile and turns the time\n",
    "vector from hours past the start date into a python datetime object\n",
    "in UTC.  It uses the dateutil parse function to turn the date_start_of_data string into a date.  \n",
    "\n",
    "This function is used in the cells below to create two dictionaries:\n",
    "\n",
    "1. **data_dict** with six keys for the 3 file/2 month combinations\n",
    "   with each (file,month) entry holding a dictionary\n",
    "   with the numpy array data for the file variables (F, UST, etc.)\n",
    "    \n",
    "2. **var_attr** with a key for each variable holding dictionaries with\n",
    "   the variable attributes (units, long name, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_date(ncfile):\n",
    "    \"\"\"\n",
    "    ncfile:  open netCDF4 Dataset\n",
    "    returns:\n",
    "       numpy array of datetime objects\n",
    "    \"\"\"\n",
    "    the_time=f.variables['time'][...]\n",
    "    start_date=f.variables['product'].date_start_of_data\n",
    "    start_date = parse(start_date)\n",
    "    time_vec=[]\n",
    "    for the_hour in the_time:\n",
    "        time_vec.append(start_date + datetime.timedelta(hours=float(the_hour)))\n",
    "    time_vec=np.array(time_vec)\n",
    "    time_vec=time_vec.reshape(-1,24,6)\n",
    "    return time_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all the files and make a dictionary with keys determined\n",
    "by the netcdf file attributes.  Initially the dictionary contains the\n",
    "filename, start_date, lat, lon and start time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_attrs(ncvar):\n",
    "    \"\"\"\n",
    "        input: open netcdf variable handle\n",
    "        output: dictionary containing name,attribute pairs\n",
    "    \"\"\"\n",
    "    attributes=ncvar.ncattrs()\n",
    "    attr_dict={}\n",
    "    for attr in attributes:\n",
    "        attr_dict[attr]=getattr(ncvar,attr)\n",
    "    return attr_dict\n",
    "    \n",
    "all_files=glob.glob('cesar*.nc')\n",
    "data_dict={}\n",
    "var_attrs={}\n",
    "for the_file in all_files:\n",
    "    if the_file.find('nubiscope') > -1:\n",
    "        continue\n",
    "    with Dataset(the_file,'r') as f:\n",
    "        details=f.variables['iso_dataset']\n",
    "        attr_dict=get_attrs(details)\n",
    "        lon=attr_dict['westbound_longitude']\n",
    "        lat=attr_dict['northbound_latitude']\n",
    "        title=attr_dict['title'].split()\n",
    "        the_time = make_date(f)\n",
    "        #\n",
    "        # turn a title like:\n",
    "        #\"CESAR surface fluxes validated and gap filled\"\n",
    "        # into the string: surface_fluxes\n",
    "        #\n",
    "        filetype='{}_{}'.format(*title[1:3])\n",
    "        start_date=f.variables['product'].date_start_of_data\n",
    "        start_date=parse(start_date)\n",
    "        start_month=start_date.strftime('%Y%m')\n",
    "    data_dict[filetype,start_month]=dict(name=the_file,timevec=the_time,lon=lon,lat=lat,\n",
    "                                        start_date=start_date)\n",
    "#\n",
    "#  lat and lon shouldn't change, use the last values for the netcdf file attribute\n",
    "#\n",
    "for name in ['lat','lon']:\n",
    "    var_attrs[name]=data_dict[filetype,start_month][name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now loop through the dictionary and add the flux and tower variables.\n",
    "Each variable is a linear vector of measurements taken every 10 minutes, and\n",
    "for tower variables, at 7 levels.\n",
    "\n",
    "The numpy command:\n",
    "var.reshape(-1,24,6,7)\n",
    "takes the linear vector and folds it into either 28,29,30,31 days (depending on monty)\n",
    "24 hours, 6 10 minute intervals, and 7 levels\n",
    "\n",
    "That allows us to do an hourly average by saying:\n",
    "var.mean(axis=2)  to average over the 6 10 minute measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting by month\n",
    "\n",
    "This cell goes through the data_dict dictionaries and combines the six\n",
    "(file,month) keys into two dictionaries, one for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# collect all the data from the three files into a dictionary indexed\n",
    "# by month called month_dict\n",
    "#\n",
    "#  use defaultdict(dict) so that every time we add a new month\n",
    "#  we create an empty dictionary to hold the variables\n",
    "#  \n",
    "#\n",
    "from collections import defaultdict\n",
    "month_dict=defaultdict(dict)\n",
    "for the_key in data_dict.keys():\n",
    "    var_dict=data_dict[the_key]\n",
    "    the_month=the_key[1]\n",
    "    print('working on: ',the_month)\n",
    "    if the_key[0] == 'tower_meteorological':\n",
    "        with Dataset(var_dict['name'],'r') as f:\n",
    "            if 'has_time' not in month_dict[the_month]:\n",
    "                month_dict[the_month]['timevec'] = var_dict['timevec']\n",
    "                month_dict[the_month]['has_time']=True\n",
    "            month_dict[the_month]['z'] = f.variables['z'][...]\n",
    "            for var in ['F','TA','TD','Q','D']:\n",
    "                month_dict[the_month][var] = f.variables[var][...].reshape(-1,24,6,7)\n",
    "                var_attrs[var]=get_attrs(f.variables[var])\n",
    "    elif the_key[0] == 'surface_fluxes': \n",
    "        with Dataset(var_dict['name'],'r') as f:\n",
    "            for var in ['H','UST','LE']:\n",
    "                month_dict[the_month][var] = f.variables[var][...].reshape(-1,24,6)\n",
    "                var_attrs[var]=get_attrs(f.variables[var])\n",
    "    elif the_key[0] == 'meteorological_surface': \n",
    "        with Dataset(var_dict['name'],'r') as f:\n",
    "            for var in ['P0','TA002','Q002','F010']:\n",
    "                month_dict[the_month][var] = f.variables[var][...].reshape(-1,24,6)\n",
    "                var_attrs[var]=get_attrs(f.variables[var])\n",
    "    elif the_key[0] == 'scanning_radiometer':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"didn't recognize {}\".format(the_key[0]))\n",
    "print('finished: ',month_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to know sunrise, sunset and solar noon to interpret our\n",
    "data.  Here is how you find these with the \n",
    "[pyephem](http://stackoverflow.com/questions/2637293/calculating-dawn-and-sunset-times-using-pyephem) module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ephem\n",
    "for the_month in month_dict.keys():\n",
    "    var='tower_meteorological'\n",
    "    start_time=month_dict[the_month]['timevec'][0,0,0]\n",
    "    cabauw=ephem.Observer()\n",
    "    cabauw.date=start_time\n",
    "    cabauw.lon = var_attrs['lon']\n",
    "    cabauw.lat = var_attrs['lat']\n",
    "    sunrise=cabauw.next_rising(ephem.Sun())\n",
    "    noon = cabauw.next_transit(ephem.Sun(),start=sunrise)\n",
    "    sunset = cabauw.next_setting(ephem.Sun())\n",
    "    print('sunrise is {} UTC'.format(sunrise))\n",
    "    print('solar noon {} UTC'.format(noon))\n",
    "    print('sunset is {} UTC'.format(sunset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.close('all')\n",
    "print('starting: ',month_dict.keys())    \n",
    "for the_month in month_dict.keys():\n",
    "    hourly_wind_avg = month_dict[the_month]['F'].mean(axis=2)\n",
    "    z=month_dict[the_month]['z']\n",
    "    hour=2\n",
    "    fig,ax=plt.subplots(1,2,figsize=(8,6))\n",
    "    ax[0].plot(hourly_wind_avg[:,hour,:].T,z)\n",
    "    ax[0].set(title='hour: {} UTC'.format(hour))\n",
    "    hour=14\n",
    "    ax[1].plot(hourly_wind_avg[:,hour,:].T,z)\n",
    "    ax[1].set(title='hour: {} UTC'.format(hour))\n",
    "    fig.suptitle('{} hourly avg winds'.format(the_month))\n",
    "\n",
    "    #\n",
    "    # date plotting tips at http://matplotlib.org/users/recipes.html\n",
    "    #\n",
    "    the_time = month_dict[the_month]['timevec']\n",
    "    H=month_dict[the_month]['H']\n",
    "    fig,ax=plt.subplots(1,1,figsize=(8,6))\n",
    "    fig.autofmt_xdate()\n",
    "    ax.plot(the_time.flat,H.flat)\n",
    "    title='sensible heat flux for {}'.format(the_month)\n",
    "    ax.set(title=title,ylabel='H $(W\\,m^{-2})$')\n",
    "print('finished plot: ',month_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint all the data into one netcdf file\n",
    "\n",
    "I want to save month_dict into a netcdf file so we don't need\n",
    "to repeat this processing but can start with a merged dataset\n",
    "merged dataset that has all days of interest and all\n",
    "instruments in a single place.   To do that, I group the measurements\n",
    "into individual days using [netcdf groups](http://unidata.github.io/netcdf4-python)\n",
    "\n",
    "I transer all the attributes I read into the var_attrs dict so I maintain\n",
    "the original metadata as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_attrs(ncvar,attr_dict):\n",
    "    for name,item in attr_dict.items():\n",
    "        if name != '_FillValue':\n",
    "            setattr(ncvar,name,item)\n",
    "    return None\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "filename='cabauw_ubc.nc'\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)   \n",
    "with Dataset(filename,'w') as ncout:\n",
    "    the_months = month_dict.keys()\n",
    "    for the_month in the_months:\n",
    "        speed=month_dict[the_month]['F']\n",
    "        days_name='days{:2d}'.format(speed.shape[0])\n",
    "        dimnames=[days_name,'hours','min10','z']\n",
    "        dim_info=zip(dimnames,speed.shape)\n",
    "        for name,length in dim_info:     \n",
    "            try:\n",
    "                ncout.createDimension(name,length) \n",
    "            except RuntimeError:\n",
    "                pass\n",
    "        nc_month='m{}'.format(the_month)\n",
    "        date_group=ncout.createGroup(nc_month)\n",
    "        setattr(date_group,'month',the_month)\n",
    "        for var in ['H','LE','UST','P0','TA002','Q002','F010']:\n",
    "            the_data=month_dict[the_month][var]\n",
    "            var_nc=date_group.createVariable(var,the_data.dtype,\n",
    "                                             [days_name,'hours','min10'])\n",
    "            var_nc[...]=the_data[...]\n",
    "            write_attrs(var_nc,var_attrs[var])\n",
    "        for var in ['TA','D','Q','TD','F']:\n",
    "            the_data=month_dict[the_month][var]\n",
    "            var_nc=date_group.createVariable(var,the_data.dtype,\n",
    "                                             [days_name,'hours','min10','z'])\n",
    "            var_nc[...]=the_data[...]\n",
    "            write_attrs(var_nc,var_attrs[var])\n",
    "\n",
    "        the_time=month_dict[the_month]['timevec']\n",
    "        float_time=np.array([item.timestamp() for item in the_time.flat])\n",
    "        float_time=float_time.reshape(-1,24,6)   \n",
    "        time_nc=date_group.createVariable('time',float_time.dtype,\n",
    "                                     [days_name,'hours','min10']) \n",
    "        time_nc[...]=float_time[...]\n",
    "        time_nc.timezone='UTC'\n",
    "        time_nc.comment='convert using datetime.fromtimestamp(var,pytz.utc)'\n",
    "        try:\n",
    "            z=month_dict[the_month]['z']\n",
    "            z_nc=ncout.createVariable('z',z.dtype,['z'])\n",
    "            z_nc[...]=z[...]\n",
    "        except RuntimeError:\n",
    "            #\n",
    "            # only create ncout z vector once\n",
    "            #\n",
    "            pass\n",
    "        ncout.history='written by read_cabauw.ipynb'\n",
    "        for var in ['lat','lon']:\n",
    "            setattr(ncout,var,float(var_attrs[var]))\n",
    "        ncout.lat_units='degrees north'\n",
    "        ncout.lon_units='degrees east'\n",
    "        filelist=[]\n",
    "        for key,value in data_dict.items():\n",
    "            filelist.append('{};'.format(value['name']))\n",
    "        filelista=np.array(filelist)\n",
    "        setattr(ncout,'filelist',filelist)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ncdump -h cabauw_ubc.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}